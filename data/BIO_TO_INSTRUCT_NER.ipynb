{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44d20cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d5cf2",
   "metadata": {},
   "source": [
    "### separate sentences (split bio file for each note to bio file for each sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d78a754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(f'./notes/*.bio') ## your dir of bio files\n",
    "i = 0\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        text = f.read()\n",
    "        lines = text.strip().split('\\n')\n",
    "\n",
    "        sentences = []\n",
    "        current_sentence = []\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                word, label = parts\n",
    "                current_sentence.append(f\"{word}\\t{label}\")\n",
    "            elif len(parts) == 1 and not parts[0].strip():\n",
    "                # Empty line, indicating the end of a sentence\n",
    "                sentences.append('\\n'.join(current_sentence))\n",
    "                current_sentence = []\n",
    "\n",
    "        # If there are any remaining sentences, add them\n",
    "        if current_sentence:\n",
    "            sentences.append('\\n'.join(current_sentence))\n",
    "\n",
    "        # Join the sentences with '\\n' and print\n",
    "        for sentence in sentences:\n",
    "            with open(f'./sentences/{i}.bio','w') as f:\n",
    "                f.write(sentence)\n",
    "            i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91985c",
   "metadata": {},
   "source": [
    "### BIO TO INSTRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88cb1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unprocessed_text(file):\n",
    "    with open(file,'r') as f_read:\n",
    "        text = ' '.join([line.split('\\t')[0] for line in f_read.read().splitlines()])\n",
    "    return text\n",
    "\n",
    "def load_processed_text(file):\n",
    "    with open(file,'r') as f_read:\n",
    "        lines = f_read.readlines()\n",
    "    \n",
    "    processed_text = ''\n",
    "    for i, line in enumerate(lines):\n",
    "        token, e_type = line.strip().split('\\t')\n",
    "        if e_type == 'O':\n",
    "            processed_text += token+' '\n",
    "            \n",
    "        if e_type.startswith('B-'):\n",
    "            if i <= len(lines)-2:\n",
    "                if lines[i+1]=='\\n' or lines[i+1].strip().split('\\t')[1]=='O' or lines[i+1].strip().split('\\t')[1].startswith('B-'):\n",
    "                    processed_text += f'<span class=\"{e_type[2:]}\">'+token+'</span> '\n",
    "                else:\n",
    "                    processed_text += f'<span class=\"{e_type[2:]}\">'+token+' '\n",
    "            else:\n",
    "                processed_text += f'<span class=\"{e_type[2:]}\">'+token+'</span> '\n",
    "            \n",
    "        if e_type.startswith('I-'):\n",
    "            if i <= len(lines)-2:\n",
    "                if lines[i+1]=='\\n' or lines[i+1].strip().split('\\t')[1]=='O' or lines[i+1].strip().split('\\t')[1].startswith('B-'):\n",
    "                    processed_text += token+'</span> '\n",
    "                else:\n",
    "                    processed_text += token+' '\n",
    "            else:\n",
    "                processed_text += token+'</span> '\n",
    "    processed_text+='<EOS>'\n",
    "    return processed_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''### Task:\n",
    "Your task is to generate an HTML version of an input text, using HTML <span> tags to mark up specific entities.\n",
    "\n",
    "### Entity Markup Guides:\n",
    "Use <span class=\"problem\"> to denote a medical problem.\n",
    "Use <span class=\"treatment\"> to denote a treatment.\n",
    "Use <span class=\"test\"> to denote a test.\n",
    "Use <span class=\"drug\"> to denote a drug.\n",
    "\n",
    "### Entity Definitions:\n",
    "Medical Problem: The abnormal condition that happens physically or mentally to a patient.\n",
    "Treatment: The procedures, interventions, and substances given to a patient for treating a problem.\n",
    "Drug: Generic or brand name of a single medication or a collective name of a group of medication.\n",
    "Test: A medical procedure performed (i) to detect or diagnose a problem, (ii) to monitor diseases, disease processes, and susceptibility, or (iii) to determine a course of treatment.\n",
    "\n",
    "### Input Text: {} <EOS>\n",
    "### Output Text:'''\n",
    "\n",
    "files = glob(f'./sentences/*.bio')\n",
    "#files = glob(f'./after_split/{split}/*.bio')\n",
    "random.seed(42)\n",
    "random.shuffle(files)\n",
    "len(files)\n",
    "\n",
    "df = pd.DataFrame(columns=['unprocessed', 'processed'])\n",
    "\n",
    "i = 0\n",
    "length = len(files)\n",
    "\n",
    "unprocessed = []\n",
    "processed = []\n",
    "for file in files:               \n",
    "    unprocessed_tmp = load_unprocessed_text(file)\n",
    "    processed_tmp = load_processed_text(file)\n",
    "\n",
    "    processed.append(processed_tmp)\n",
    "    unprocessed.append(prompt.format(unprocessed_tmp))\n",
    "\n",
    "    length_list.append(len(unprocessed_tmp.split(' '))+len(processed_tmp.split(' ')))\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame({'unprocessed': unprocessed, 'processed': processed})], ignore_index=True)\n",
    "\n",
    "#df.to_csv(f'document_level_main_{split}.csv', index=False)\n",
    "df.to_csv(f'NER.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
