{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de1bc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbee31c33aff4293bca78ebcac002439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "There was a specific connection error when trying to load meta-llama/Meta-Llama-3-8B-Instruct:\n401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json (Request ID: Root=1-67c253e6-4aca3abc5cc7e31507d1ac58;978ccda7-d16d-4cbd-8b43-26e88d1a5e99)\n\nInvalid credentials in Authorization header",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:342\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1486\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m   1483\u001b[0m ):\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:280\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 280\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:304\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    303\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 304\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:481\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json (Request ID: Root=1-67c253e6-4aca3abc5cc7e31507d1ac58;978ccda7-d16d-4cbd-8b43-26e88d1a5e99)\n\nInvalid credentials in Authorization header",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkiwillama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interface, settings, train, utils\n\u001b[1;32m      4\u001b[0m gpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1,2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gpus\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/kiwillama/train.py:45\u001b[0m\n\u001b[1;32m     29\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m     data_files\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     39\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m     40\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/yhu5/huggingface_models/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m base_model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     56\u001b[0m base_model \u001b[38;5;241m=\u001b[39m prepare_model_for_kbit_training(base_model)\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:526\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 526\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1075\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1073\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1075\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1077\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:594\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/transformers/configuration_utils.py:653\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m~/Documents/code/Kiwi-LLaMA/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:406\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: There was a specific connection error when trying to load meta-llama/Meta-Llama-3-8B-Instruct:\n401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/resolve/main/config.json (Request ID: Root=1-67c253e6-4aca3abc5cc7e31507d1ac58;978ccda7-d16d-4cbd-8b43-26e88d1a5e99)\n\nInvalid credentials in Authorization header"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kiwillama import interface, settings, train, utils\n",
    "\n",
    "gpus = '1,2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "\n",
    "model_name = './models/Llama-3-8b-mix-2epoch/merged/'\n",
    "\n",
    "device_map = [f\"cuda:{i}\" for i in gpus.split(\",\")]\n",
    "\n",
    "from vllm import LLM,SamplingParams\n",
    "sampling_params = SamplingParams(max_tokens=512,stop='<EOS>',temperature=0)\n",
    "llm = LLM(model=f\"{model_name}\", tensor_parallel_size=len(device_map))  # Create an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2a5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "prompt = '''### Task:\n",
    "Your task is to generate an HTML version of an input text, using HTML <span> tags to mark up specific entities.\n",
    "\n",
    "### Entity Markup Guides:\n",
    "Use <span class=\"problem\"> to denote a medical problem.\n",
    "Use <span class=\"treatment\"> to denote a treatment.\n",
    "Use <span class=\"test\"> to denote a test.\n",
    "Use <span class=\"drug\"> to denote a drug.\n",
    "\n",
    "### Entity Definitions:\n",
    "Medical Problem: The abnormal condition that happens physically or mentally to a patient.\n",
    "Treatment: The procedures, interventions, and substances given to a patient for treating a problem.\n",
    "Drug: Generic or brand name of a single medication or a collective name of a group of medication.\n",
    "Test: A medical procedure performed (i) to detect or diagnose a problem, (ii) to monitor diseases, disease processes, and susceptibility, or (iii) to determine a course of treatment.\n",
    "\n",
    "### Input Text: {} <EOS>\n",
    "### Output Text:'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6e9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_list(input_list, batch_size):\n",
    "    batched_list = []\n",
    "    for i in range(0, len(input_list), batch_size):\n",
    "        batched_list.append(input_list[i:i + batch_size])\n",
    "    return batched_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316e0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "import time\n",
    "\n",
    "def get_gpu_memory_usage():\n",
    "    nvmlInit()\n",
    "    device_count = nvmlDeviceGetCount()  # Get number of GPUs\n",
    "    memory_usage = []\n",
    "    for i in [5,6]:\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        memory_usage.append(info.used / 1024 ** 2)  # Convert to MB\n",
    "    return memory_usage\n",
    "\n",
    "def get_gpu_power_usage():\n",
    "    device_count = nvmlDeviceGetCount()  # Get number of GPUs\n",
    "    power_usage = []\n",
    "    for i in [5,6]:\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        power = nvmlDeviceGetPowerUsage(handle)  # Returns power in milliwatts\n",
    "        power_usage.append(power / 1000)  # Convert to watts\n",
    "    return power_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de94a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def group_relations(tuples_set):\n",
    "    grouped_tuples = {}\n",
    "    for pair in tuples_set:\n",
    "        key = pair[0]  # The first tuple of the pair\n",
    "        if key in grouped_tuples:\n",
    "            grouped_tuples[key].append(pair[1])\n",
    "        else:\n",
    "            grouped_tuples[key] = [pair[1]]\n",
    "            \n",
    "    # Sorting the values in each group in descending order based on the second value of the tuple\n",
    "    sorted_grouped_tuples = {}\n",
    "    for key, values in grouped_tuples.items():\n",
    "        sorted_grouped_tuples[key] = sorted(values, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_grouped_tuples\n",
    "\n",
    "def replace_entities_with_types(sent, entities):\n",
    "    sent_text = str(sent)\n",
    "    if isinstance(entities, list):\n",
    "        for e in entities:\n",
    "            ent_type, start, end =e\n",
    "            sent_text = sent_text[:start - sent.start_char]+f'<span class=\"{ent_type}\">{sent_text[start - sent.start_char:end - sent.start_char]}</span>'+sent_text[end - sent.start_char:] \n",
    "    else:\n",
    "        ent_type, start, end =entities\n",
    "        sent_text = sent_text[:start - sent.start_char]+f'<span class=\"{ent_type}\">{sent_text[start - sent.start_char:end - sent.start_char]}</span>'+sent_text[end - sent.start_char:] \n",
    "    return sent_text\n",
    "\n",
    "def sentence_relations(text,entities, relations, nlp):\n",
    "    test_prompt = '''### Task:\n",
    "    Your task is to mark up modifier entities related to the entity marked with <span> tag in the input text.\n",
    "    \n",
    "    ### Entity Markup Guide:\n",
    "    Use <span class=\"labvalue\"> to denote a numeric value or a normal description of the result of a lab test.\n",
    "    Use <span class=\"reference_range\"> to denote the range or interval of values that are deemed as normal for a test in a healthy person.\n",
    "    Use <span class=\"negation\"> to denote the phrase that indicates the absence of an entity.\n",
    "    Use <span class=\"temporal\"> to denote a calendar date, time, or duration related to a test.\n",
    "\n",
    "    ### Input Text: {} <EOS>\n",
    "    ### Output Text:'''\n",
    "    \n",
    "    drug_prompt = '''### Task:\n",
    "    Your task is to mark up modifier entities related to the entity marked with <span> tag in the input text.\n",
    "\n",
    "    ### Entity Markup Guide:\n",
    "    Use <span class=\"form\"> to denote the form of drug.\n",
    "    Use <span class=\"frequency\"> to denote the frequency of taking a drug.\n",
    "    Use <span class=\"dosage\"> to denote the amount of active ingredient from the number of drugs prescribed.\n",
    "    Use <span class=\"duration\"> to denote the time period a patient should take a drug.\n",
    "    Use <span class=\"strength\"> to denote the amount of active ingredient in a given dosage form.\n",
    "    Use <span class=\"route\"> to denote the way by which a drug, fluid, poison, or other substance is taken into the body.\n",
    "    Use <span class=\"negation\"> to denote the phrase that indicates the absence of an entity.\n",
    "    Use <span class=\"temporal\"> to denote a calendar date, time, or duration related to a drug.\n",
    "\n",
    "    ### Input Text: {} <EOS>\n",
    "    ### Output Text:'''\n",
    "\n",
    "    problem_prompt = '''### Task:\n",
    "    Your task is to mark up modifier entities related to the entity marked with <span> tag in the input text.\n",
    "\n",
    "    ### Entity Markup Guide:\n",
    "    Use <span class=\"uncertain\"> to denote a measure of doubt.\n",
    "    Use <span class=\"condition\"> to denote a phrase that indicates the problems existing in a certain situation.\n",
    "    Use <span class=\"subject\"> to denote the person entity who is experiencing the disorder.\n",
    "    Use <span class=\"negation\"> to denote the phrase that indicates the absence of an entity.\n",
    "    Use <span class=\"bodyloc\"> to denote the location on the body where the observation is present.\n",
    "    Use <span class=\"severity\"> to denote the degree of intensity of a clinical condition.\n",
    "    Use <span class=\"temporal\"> to denote a calendar date, time, or duration related to a problem.\n",
    "    Use <span class=\"course\"> to denote the development or alteration of a problem.\n",
    "\n",
    "    ### Input Text: {} <EOS>\n",
    "    ### Output Text:'''\n",
    "    \n",
    "    treatment_prompt = '''### Task:\n",
    "    Your task is to mark up modifier entities related to the entity marked with <span> tag in the input text.\n",
    "\n",
    "    ### Entity Markup Guide:\n",
    "    Use <span class=\"temporal\"> to denote a calendar date, time, or duration related to a treatment.\n",
    "    Use <span class=\"negation\"> to denote the phrase that indicates the absence of an entity.\n",
    "\n",
    "    ### Input Text: {} <EOS>\n",
    "    ### Output Text:'''\n",
    "    df = pd.DataFrame(columns=['main_entity','unprocessed', 'processed'])\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    sentences = list(doc.sents)\n",
    "    sentence_relations = []\n",
    "\n",
    "    unprocessed = []\n",
    "    processed = []\n",
    "    main_entities = []\n",
    "    for sent in sentences:\n",
    "        sent_relations = set()\n",
    "        sent_entities = []\n",
    "\n",
    "        # Check if entities are in the current sentence\n",
    "        for ent_id, ent in entities.items():\n",
    "            if ent[1] >= sent.start_char and ent[2] <= sent.end_char:\n",
    "                sent_entities.append(ent)\n",
    "                                \n",
    "        # Check for existing relations in the current sentence\n",
    "        for rel in relations:\n",
    "            rel_type, ent1, ent2 = rel\n",
    "            if ent1 in sent_entities and ent2 in sent_entities:\n",
    "                sent_relations.add((ent1, ent2))\n",
    "        sent_relations = group_relations(sent_relations)\n",
    "        \n",
    "        for main_entity, modifier_entities in sent_relations.items():\n",
    "            #print (main_entity[0])\n",
    "            main_entities.append(main_entity[0])\n",
    "            # Replace entity mentions with their types\n",
    "            modifier_sent_text = replace_entities_with_types(sent, modifier_entities).replace('\\n',' ')\n",
    "            main_entity_sent_text = replace_entities_with_types(sent, main_entity).replace('\\n',' ')\n",
    "            \n",
    "            if main_entity[0] == 'problem':\n",
    "                unprocessed.append(problem_prompt.format(main_entity_sent_text))\n",
    "                processed.append(modifier_sent_text+' <EOS>')\n",
    "            if main_entity[0] == 'drug':\n",
    "                unprocessed.append(drug_prompt.format(main_entity_sent_text))\n",
    "                processed.append(modifier_sent_text+' <EOS>')\n",
    "            if main_entity[0] == 'treatment':\n",
    "                unprocessed.append(treatment_prompt.format(main_entity_sent_text))\n",
    "                processed.append(modifier_sent_text+' <EOS>')\n",
    "            if main_entity[0] == 'test':\n",
    "                unprocessed.append(test_prompt.format(main_entity_sent_text))\n",
    "                processed.append(modifier_sent_text+' <EOS>')\n",
    "        # check for non-existing relations in current sentence\n",
    "        for entity in sent_entities:\n",
    "            if entity not in sent_relations and entity[0] in ['problem','treatment','test','drug']:\n",
    "                #print (entity[0])\n",
    "                main_entities.append(entity[0])\n",
    "                main_entity_sent_text = replace_entities_with_types(sent, entity).replace('\\n',' ')\n",
    "                sent_text = str(sent).replace('\\n',' ')\n",
    "                if entity[0] == 'problem':\n",
    "                    unprocessed.append(problem_prompt.format(main_entity_sent_text))\n",
    "                    processed.append(sent_text+' <EOS>')\n",
    "                if entity[0] == 'drug':\n",
    "                    unprocessed.append(drug_prompt.format(main_entity_sent_text))\n",
    "                    processed.append(sent_text+' <EOS>')\n",
    "                if entity[0] == 'treatment':\n",
    "                    unprocessed.append(treatment_prompt.format(main_entity_sent_text))\n",
    "                    processed.append(sent_text+' <EOS>')\n",
    "                if entity[0] == 'test':\n",
    "                    unprocessed.append(test_prompt.format(main_entity_sent_text))\n",
    "                    processed.append(sent_text+' <EOS>')\n",
    "    df = pd.concat([df, pd.DataFrame({'main_entity':main_entities,'unprocessed': unprocessed, 'processed': processed})], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def read_brat_files(txt_path, ann_path):\n",
    "    with open(txt_path, \"r\",encoding='utf-8') as txt_file:\n",
    "        text = txt_file.read()\n",
    "    \n",
    "    entities = {}\n",
    "    relations = []\n",
    "    \n",
    "    new_lines = reorg_annfile(ann_path)\n",
    "    for line in new_lines:\n",
    "        try:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if parts[0].startswith('T'):\n",
    "                try:\n",
    "                    ent_id, ent_info = parts[0], parts[1]\n",
    "                    ent_type, start, end = ent_info.split(' ')\n",
    "                    ent_type = ent_type.lower()\n",
    "                    entities[ent_id] = (ent_type, int(start), int(end))\n",
    "                except:\n",
    "\n",
    "                    print (new_lines)\n",
    "\n",
    "                    raise\n",
    "            elif parts[0].startswith('R'):\n",
    "                rel_id, rel_type, arg1, arg2 = [parts[0]]+parts[1].split(' ')\n",
    "                relations.append((rel_type, entities[arg1.split(':')[1]], entities[arg2.split(':')[1]]))\n",
    "        except:\n",
    "            continue\n",
    "    return text, entities, relations\n",
    "\n",
    "def follows_pattern(s):\n",
    "    # Define the regex pattern\n",
    "    pattern = r'^[TR]\\d+'\n",
    "    \n",
    "    # Use re.match to check if the string matches the pattern\n",
    "    if re.match(pattern, s):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def reorg_annfile(file):\n",
    "    new_file=[]\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "    skip = False\n",
    "    for i,line in enumerate(lines):\n",
    "        if i <= len(lines)-2:\n",
    "            if not follows_pattern(lines[i+1]):\n",
    "                new_file.append(line.strip()+' '+lines[i+1].strip()+'\\n')\n",
    "                skip = True\n",
    "            else:\n",
    "                if not skip:\n",
    "                    new_file.append(line)\n",
    "                else:\n",
    "                    skip = False\n",
    "                    pass\n",
    "                \n",
    "        else:\n",
    "            if not skip:\n",
    "                new_file.append(line)\n",
    "            else:\n",
    "                skip = False\n",
    "                pass\n",
    "    return new_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acff4399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i2b2\n",
      "Average GPU memory usage (per GPU): [73329.25, 73329.25]\n",
      "Total GPU time: 5.51078724861145 seconds (~0.00 hours)\n",
      "Average GPU power consumption (per GPU): [294.42699999999996, 307.4886666666667]\n",
      "Total energy consumption (per GPU): [0.4473378883051873, 0.46597867640925783] Wh\n"
     ]
    }
   ],
   "source": [
    "\n",
    "separator = '\\t'\n",
    "batch_size = 100\n",
    "for dataset in ['i2b2']:\n",
    "    print(dataset)\n",
    "    files = glob(f'../data/test/{dataset}/*.bio')\n",
    "\n",
    "    prompts = []\n",
    "    for i, file in enumerate(files):\n",
    "        with open(file, 'r', encoding='utf-8') as f_read:\n",
    "            text = ' '.join([line.split(separator)[0] for line in f_read.read().splitlines()])\n",
    "        file_name = file.split('/')[-1].split('.')[0]\n",
    "        prompts.append(prompt.format(text))\n",
    "\n",
    "    prompts_list = batch_list(prompts, batch_size)\n",
    "\n",
    "    outputs = []\n",
    "    # Initialize tracking variables\n",
    "    gpu_memory_usage_per_batch = []\n",
    "    gpu_time_per_batch = []\n",
    "    gpu_power_usage_per_batch = []\n",
    "\n",
    "    # Start your batch processing loop\n",
    "    for i, prompt_list in enumerate(prompts_list):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Record initial GPU power usage\n",
    "        initial_power = get_gpu_power_usage()\n",
    "\n",
    "        # Generate the output\n",
    "        output = llm.generate(prompt_list, sampling_params, use_tqdm=False)\n",
    "\n",
    "        # Record final GPU power usage\n",
    "        final_power = get_gpu_power_usage()\n",
    "\n",
    "        end_time = time.time()\n",
    "        gpu_time = end_time - start_time\n",
    "        gpu_time_per_batch.append(gpu_time)\n",
    "\n",
    "        # Record GPU memory usage and power consumption after the batch\n",
    "        gpu_memory_used = get_gpu_memory_usage()\n",
    "        gpu_memory_usage_per_batch.append(gpu_memory_used)\n",
    "\n",
    "        # Calculate average power usage for each GPU\n",
    "        avg_power_usage = [(init + final) / 2 for init, final in zip(initial_power, final_power)]\n",
    "        gpu_power_usage_per_batch.append(avg_power_usage)\n",
    "\n",
    "        outputs += output\n",
    "\n",
    "    # Calculate average GPU memory usage across all GPUs\n",
    "    if gpu_memory_usage_per_batch:\n",
    "        avg_gpu_memory_usage = [sum(mem) / len(gpu_memory_usage_per_batch) for mem in zip(*gpu_memory_usage_per_batch)]\n",
    "        print(f'Average GPU memory usage (per GPU): {avg_gpu_memory_usage}')\n",
    "\n",
    "    # Calculate total GPU time\n",
    "    total_gpu_time = sum(gpu_time_per_batch)\n",
    "    print(f'Total GPU time: {total_gpu_time} seconds (~{total_gpu_time / 3600:.2f} hours)')\n",
    "\n",
    "    # Calculate average power consumption per GPU\n",
    "    if gpu_power_usage_per_batch:\n",
    "        avg_gpu_power_usage = [sum(power) / len(gpu_power_usage_per_batch) for power in zip(*gpu_power_usage_per_batch)]\n",
    "        print(f'Average GPU power consumption (per GPU): {avg_gpu_power_usage}')\n",
    "\n",
    "    # Calculate total energy consumption per GPU\n",
    "    total_energy_consumption = [\n",
    "        sum([power[i] * time / 3600 for power, time in zip(gpu_power_usage_per_batch, gpu_time_per_batch)])\n",
    "        for i in range(len(avg_gpu_power_usage))\n",
    "    ]\n",
    "    print(f'Total energy consumption (per GPU): {total_energy_consumption} Wh')\n",
    "    \n",
    "    for i,seq in enumerate(outputs):\n",
    "        file_name = files[i].split('/')[-1].split('.')[0]\n",
    "        with open(f'./output/NER/{file_name}.html','w',encoding='utf-8') as f_write:\n",
    "            f_write.write(seq.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000180ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "Average GPU memory usage (per GPU): [73329.25, 73329.25]\n",
      "Total GPU time: 12.960270166397095 seconds (~0.00 hours)\n",
      "Average GPU power consumption (per GPU): [324.594375, 339.533]\n",
      "Total energy consumption (per GPU): [1.1455124690044256, 1.2499108208171528] Wh\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dataset in ['i2b2_test']:\n",
    "    # Load the SpaCy model for sentence tokenization\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    \n",
    "    txt = glob(f'../data/RE/test_LLM/*.txt')\n",
    "\n",
    "    relation_types = []\n",
    "    entity_pairs = []\n",
    "    df = pd.DataFrame(columns=['main_entity','unprocessed', 'processed'])\n",
    "    for txt_path in txt:\n",
    "        filename = txt_path.split('/')[-1].split('.')[0]\n",
    "        ann_path = f'../data/RE/test_LLM/{filename}.ann'\n",
    "\n",
    "        # Read the Brat files and extract the entities and relations\n",
    "        text, entities, relations = read_brat_files(txt_path, ann_path)\n",
    "\n",
    "        # Extract sentence relations\n",
    "        df = pd.concat([df, sentence_relations(text, entities, relations, nlp)])\n",
    "    \n",
    "    print (len(df))\n",
    "        \n",
    "    unprocessed = []\n",
    "    for index, row in df.iterrows():\n",
    "        unprocessed.append(row['unprocessed'])\n",
    "        \n",
    "\n",
    "    batch_size = 100\n",
    "    separator = '\\t'\n",
    "    \n",
    "    prompts_list = batch_list(unprocessed, batch_size)\n",
    "\n",
    "    outputs = []\n",
    "    # Initialize tracking variables\n",
    "    gpu_memory_usage_per_batch = []\n",
    "    gpu_time_per_batch = []\n",
    "    gpu_power_usage_per_batch = []\n",
    "\n",
    "    # Start your batch processing loop\n",
    "    for i, prompt_list in enumerate(prompts_list):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Record initial GPU power usage\n",
    "        initial_power = get_gpu_power_usage()\n",
    "\n",
    "        # Generate the output\n",
    "        output = llm.generate(prompt_list, sampling_params, use_tqdm=False)\n",
    "\n",
    "        # Record final GPU power usage\n",
    "        final_power = get_gpu_power_usage()\n",
    "\n",
    "        end_time = time.time()\n",
    "        gpu_time = end_time - start_time\n",
    "        gpu_time_per_batch.append(gpu_time)\n",
    "\n",
    "        # Record GPU memory usage and power consumption after the batch\n",
    "        gpu_memory_used = get_gpu_memory_usage()\n",
    "        gpu_memory_usage_per_batch.append(gpu_memory_used)\n",
    "\n",
    "        # Calculate average power usage for each GPU\n",
    "        avg_power_usage = [(init + final) / 2 for init, final in zip(initial_power, final_power)]\n",
    "        gpu_power_usage_per_batch.append(avg_power_usage)\n",
    "\n",
    "        outputs += output\n",
    "\n",
    "    # Calculate average GPU memory usage across all GPUs\n",
    "    if gpu_memory_usage_per_batch:\n",
    "        avg_gpu_memory_usage = [sum(mem) / len(gpu_memory_usage_per_batch) for mem in zip(*gpu_memory_usage_per_batch)]\n",
    "        print(f'Average GPU memory usage (per GPU): {avg_gpu_memory_usage}')\n",
    "\n",
    "    # Calculate total GPU time\n",
    "    total_gpu_time = sum(gpu_time_per_batch)\n",
    "    print(f'Total GPU time: {total_gpu_time} seconds (~{total_gpu_time / 3600:.2f} hours)')\n",
    "\n",
    "    # Calculate average power consumption per GPU\n",
    "    if gpu_power_usage_per_batch:\n",
    "        avg_gpu_power_usage = [sum(power) / len(gpu_power_usage_per_batch) for power in zip(*gpu_power_usage_per_batch)]\n",
    "        print(f'Average GPU power consumption (per GPU): {avg_gpu_power_usage}')\n",
    "\n",
    "    # Calculate total energy consumption per GPU\n",
    "    total_energy_consumption = [\n",
    "        sum([power[i] * time / 3600 for power, time in zip(gpu_power_usage_per_batch, gpu_time_per_batch)])\n",
    "        for i in range(len(avg_gpu_power_usage))\n",
    "    ]\n",
    "    print(f'Total energy consumption (per GPU): {total_energy_consumption} Wh')\n",
    "    \n",
    "    for i,seq in enumerate(outputs):\n",
    "        with open(f'./output/RE/{i}.html','w',encoding='utf-8') as f_write:\n",
    "            f_write.write(seq.outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13f122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
